# ClasificaciÃ³n de Mensajes de Odio en Redes Sociales

Este proyecto tiene como objetivo desarrollar un modelo de aprendizaje automÃ¡tico capaz de identificar mensajes de odio en redes sociales, particularmente en espaÃ±ol, a partir de datos originalmente disponibles en inglÃ©s. Esta herramienta puede ser Ãºtil para moderaciÃ³n automÃ¡tica y anÃ¡lisis de contenido daÃ±ino en plataformas sociales.

## ğŸ§  Â¿QuÃ© es un discurso de odio?

Un discurso de odio es cualquier mensaje ofensivo dirigido a una persona o grupo por caracterÃ­sticas inherentes como raza, gÃ©nero, religiÃ³n, orientaciÃ³n sexual u origen nacional, y que puede poner en riesgo la paz social.

---

## ğŸ“Œ PropÃ³sito del Proyecto

Dado el volumen diario de mensajes en redes sociales, es fundamental identificar y clasificar los discursos de odio para alertar o sancionar comportamientos tÃ³xicos. Nuestro objetivo fue crear un clasificador que distinga entre mensajes de odio y mensajes inofensivos.

---

## ğŸ“Š Conjunto de Datos

Se utilizaron mÃºltiples bases de datos pÃºblicas extraÃ­das de Kaggle, la mayorÃ­a provenientes de la red social â€œXâ€ (antes Twitter). Se seleccionaron seis categorÃ­as principales:

- **Sexismo**: 22,407 mensajes
- **Racismo**: 18,167 mensajes
- **ReligiÃ³n**: 16,088 mensajes
- **OrientaciÃ³n sexual / identidad de gÃ©nero**: 18,031 mensajes
- **Origen / xenofobia**: 11,487 mensajes
- **No odio**: 23,053 mensajes

âš ï¸ Para facilitar la traducciÃ³n al espaÃ±ol, se seleccionaron 10,000 ejemplos por categorÃ­a y se tradujeron usando la API de Google Translate.

---

## ğŸ§¹ Preprocesamiento de Datos

Las etapas de limpieza incluyeron:

- EliminaciÃ³n de caracteres extraÃ±os (como errores de codificaciÃ³n)
- ConversiÃ³n a minÃºsculas
- RemociÃ³n de acentos, signos de puntuaciÃ³n y nÃºmeros
- EliminaciÃ³n de menciones `@user`
- DetecciÃ³n y eliminaciÃ³n de duplicados
- TokenizaciÃ³n, lematizaciÃ³n y stemming
- VectorizaciÃ³n usando **TF-IDF**

---

## ğŸ§ª Modelado y EvaluaciÃ³n

Se probaron mÃºltiples algoritmos de clasificaciÃ³n multiclase, optando finalmente por **Random Forest** debido a su capacidad para manejar caracterÃ­sticas comunes entre clases sin sobreajuste significativo.

### ğŸ“Œ MÃ©tricas del Mejor Modelo:

- **Accuracy**: 0.84  
- **Precision**: 0.83  
- **Recall**: 0.84  
- **F1 Score**: 0.83  

Entrenado con 3 semillas distintas y validaciÃ³n cruzada (5-fold), se obtuvo un desempeÃ±o consistente. Los hiperparÃ¡metros Ã³ptimos se seleccionaron usando `GridSearchCV`.

### ğŸ” DesempeÃ±o por CategorÃ­a:

| CategorÃ­a     | PrecisiÃ³n |
|---------------|-----------|
| Sexismo       | 0.73      |
| No Odio       | 0.81      |
| Origen        | 0.89      |
| Racismo       | 0.89      |
| ReligiÃ³n      | 0.91      |
| OrientaciÃ³n   | 0.65      |

---

## ğŸ” Visualizaciones

- **Nubes de palabras (WordClouds)** para cada categorÃ­a.
- **Diagramas de dispersiÃ³n (PCA)** que muestran la separabilidad entre clases.
- **Matriz de confusiÃ³n** y **curvas de aprendizaje** para validar la calidad del modelo.

---

## ğŸ“Œ ConclusiÃ³n

El modelo funciona adecuadamente, especialmente en la detecciÃ³n de mensajes **no ofensivos**, lo que es crucial para evitar sanciones errÃ³neas. Se observÃ³ menor precisiÃ³n en categorÃ­as como **sexismo** y **orientaciÃ³n**, lo cual podrÃ­a mejorarse con una mayor cantidad de datos representativos.

---

## ğŸ‘©â€ğŸ’» Autores

- Ana Cristina Cuevas GarcÃ­a  
- Derek SaÃºl MorÃ¡n PÃ©rez  
- Emiliano VicaÃ±a GarcÃ­a  
- Curso: Inteligencia Artificial 7164  

---

## ğŸ“‚ Archivos Clave

- `ClasificaciÃ³n de Mensajes de Odio.ipynb`: cuaderno Jupyter con el cÃ³digo completo del proyecto.
- `README.md`: este archivo.
- `datos/`: (no incluido aquÃ­) se espera que contenga las bases de datos ya traducidas y procesadas.

---

## ğŸ“„ Licencia

Este proyecto es de carÃ¡cter acadÃ©mico. No se garantiza el uso en entornos productivos sin validaciÃ³n adicional.

